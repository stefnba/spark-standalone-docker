{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/18 17:49:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "| John| 28|\n",
      "|Alice| 35|\n",
      "|  Bob| 42|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"spark://spark-master:7077\")\n",
    "    .appName(\"Testing PySpark Example\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "data = [(\"John\", 28), (\"Alice\", 35), (\"Bob\", 42)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------------+------+\n",
      "|      Date| Open| High|  Low|Close|Adjusted_close|Volume|\n",
      "+----------+-----+-----+-----+-----+--------------+------+\n",
      "|1980-01-02|493.5|493.5|493.5|493.5|         493.5|     0|\n",
      "|1980-01-03|485.7|485.7|485.7|485.7|         485.7|     0|\n",
      "|1980-01-04|491.8|491.8|491.8|491.8|         491.8|     0|\n",
      "|1980-01-07|492.5|492.5|492.5|492.5|         492.5|     0|\n",
      "|1980-01-08|494.1|494.1|494.1|494.1|         494.1|     0|\n",
      "|1980-01-09|  498|  498|  498|  498|           498|     0|\n",
      "|1980-01-10|497.2|497.2|497.2|497.2|         497.2|     0|\n",
      "|1980-01-11|495.9|495.9|495.9|495.9|         495.9|     0|\n",
      "|1980-01-14|  493|  493|  493|  493|           493|     0|\n",
      "|1980-01-15|492.6|492.6|492.6|492.6|         492.6|     0|\n",
      "|1980-01-16|491.4|491.4|491.4|491.4|         491.4|     0|\n",
      "|1980-01-17|489.6|489.6|489.6|489.6|         489.6|     0|\n",
      "|1980-01-18|484.2|484.2|484.2|484.2|         484.2|     0|\n",
      "|1980-01-21|483.1|483.1|483.1|483.1|         483.1|     0|\n",
      "|1980-01-22|488.7|488.7|488.7|488.7|         488.7|     0|\n",
      "|1980-01-23|490.8|490.8|490.8|490.8|         490.8|     0|\n",
      "|1980-01-24|496.5|496.5|496.5|496.5|         496.5|     0|\n",
      "|1980-01-25|494.3|494.3|494.3|494.3|         494.3|     0|\n",
      "|1980-01-28|492.6|492.6|492.6|492.6|         492.6|     0|\n",
      "|1980-01-29|494.5|494.5|494.5|494.5|         494.5|     0|\n",
      "+----------+-----+-----+-----+-----+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(\"GDAXI.INDX.csv\", header=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
