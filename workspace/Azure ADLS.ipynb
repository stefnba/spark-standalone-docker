{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-380ae62a-170c-4a37-867b-34dfdfe9062a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.2.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/3.3.1/hadoop-azure-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-azure;3.3.1!hadoop-azure.jar (40ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/7.0.1/azure-storage-7.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#azure-storage;7.0.1!azure-storage.jar (37ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1!hadoop-shaded-guava.jar (76ms)\n",
      "downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util-ajax/9.4.40.v20210413/jetty-util-ajax-9.4.40.v20210413.jar ...\n",
      "\t[SUCCESSFUL ] org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413!jetty-util-ajax.jar (19ms)\n",
      "downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...\n",
      "\t[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (28ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.10.5!jackson-core.jar(bundle) (33ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/azure-keyvault-core/1.0.0/azure-keyvault-core-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#azure-keyvault-core;1.0.0!azure-keyvault-core.jar (22ms)\n",
      "downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.40.v20210413/jetty-util-9.4.40.v20210413.jar ...\n",
      "\t[SUCCESSFUL ] org.eclipse.jetty#jetty-util;9.4.40.v20210413!jetty-util.jar (29ms)\n",
      ":: resolution report :: resolve 6601ms :: artifacts dl 292ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.2.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   23  |   8   |   8   |   0   ||   23  |   8   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-380ae62a-170c-4a37-867b-34dfdfe9062a\n",
      "\tconfs: [default]\n",
      "\t8 artifacts copied, 15 already retrieved (6006kB/12ms)\n",
      "23/12/20 11:06:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/20 11:06:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/12/20 11:06:38 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/12/20 11:06:53 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/12/20 11:07:08 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/12/20 11:07:23 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/12/20 11:07:38 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/12/20 11:07:53 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----------+--------+--------+------------+------------+\n",
      "| Code|                Name|    Country|Exchange|Currency|        Type|        Isin|\n",
      "+-----+--------------------+-----------+--------+--------+------------+------------+\n",
      "|1ARKG|LS ARK Genomic Re...|Netherlands|      AS|     EUR|         ETF|XS2399368062|\n",
      "| 2MSF|Leverage Shares 2...|Netherlands|      AS|     EUR|         ETF|IE00BF03XY85|\n",
      "| 3AMZ|Leverage Shares 3...|Netherlands|      AS|     EUR|         ETF|        NULL|\n",
      "|3ARKK|   3X ARK INNOVATION|Netherlands|      AS|     EUR|         ETF|XS2399368658|\n",
      "| 3NIO|         3x Long NIO|Netherlands|      AS|     EUR|         ETF|XS2399365472|\n",
      "| 3PLT|Leverage Shares 3...|Netherlands|      AS|     EUR|         ETF|XS2337085851|\n",
      "| AALB|Aalberts Industri...|Netherlands|      AS|     EUR|Common Stock|NL0000852564|\n",
      "|  ABN|   ABN Amro Group NV|Netherlands|      AS|     EUR|Common Stock|NL0011540547|\n",
      "|ACOMO|Amsterdam Commodi...|Netherlands|      AS|     EUR|Common Stock|NL0000313286|\n",
      "|   AD|Koninklijke Ahold...|Netherlands|      AS|     EUR|Common Stock|NL0011794037|\n",
      "|ADYEN|            Adyen NV|Netherlands|      AS|     EUR|Common Stock|NL0012969182|\n",
      "| AGGD|iShares Global Ag...|Netherlands|      AS|     USD|         ETF|IE000HQY8R78|\n",
      "| AGGE|iShares Global Ag...|Netherlands|      AS|     USD|         ETF|IE000U6US1Q0|\n",
      "| AGGH|iShares Core Glob...|    Germany|      AS|     EUR|         ETF|IE00BDBRDM35|\n",
      "|  AGN|            Aegon NV|Netherlands|      AS|     EUR|Common Stock|NL0000303709|\n",
      "| AGUG|iShares Core Glob...|Netherlands|      AS|     USD|         ETF|IE00BMGNVD65|\n",
      "| AJAX|         AFC Ajax NV|Netherlands|      AS|     EUR|Common Stock|NL0000018034|\n",
      "| AKZA|       Akzo Nobel NV|Netherlands|      AS|     EUR|Common Stock|NL0013267909|\n",
      "|ALFEN|     Alfen Beheer BV|Netherlands|      AS|     EUR|Common Stock|NL0012817175|\n",
      "|ALLFG|  Allfunds Group Ltd|Netherlands|      AS|     EUR|Common Stock|GB00BNTJ3546|\n",
      "+-----+--------------------+-----------+--------+--------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "secret = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "\n",
    "container = \"raw\"\n",
    "path = \"security/EodHistoricalData/exchange=AS/year=2023/month=10/day=20/20231020-160221__security__EodHistoricalData__AS.csv\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"spark://spark-master:7077\")\n",
    "    .appName(\"Testing Azure\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.apache.hadoop:hadoop-azure:3.3.1\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{account_name}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.oauth.provider.type.{account_name}.dfs.core.windows.net\",\n",
    "    \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    ")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.oauth2.client.id.{account_name}.dfs.core.windows.net\",\n",
    "    client_id,\n",
    ")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.oauth2.client.secret.{account_name}.dfs.core.windows.net\",\n",
    "    secret,\n",
    ")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.oauth2.client.endpoint.{account_name}.dfs.core.windows.net\",\n",
    "    f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\",\n",
    ")\n",
    "\n",
    "\n",
    "test_data = spark.read.format(\"csv\").load(\n",
    "    f\"abfs://{container}@{account_name}.dfs.core.windows.net/{path}\",\n",
    "    header=True,\n",
    ")\n",
    "\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.write.mode(\"overwrite\").partitionBy(\"Country\", \"Exchange\").parquet(\n",
    "    f\"abfss://{container}@{account_name}.dfs.core.windows.net/write_back\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"parquet\").load(\n",
    "    f\"abfss://{container}@{account_name}.dfs.core.windows.net/write_back\",\n",
    ").createOrReplaceTempView(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "SELECT Type AS type, COUNT(*) AS count FROM table WHERE Isin IS NULL GROUP BY Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
